# Алгоритмы
1. временная сложность (time complexity) — это максимальное возможное количество выполненных алгоритмом элементарных операций
1. ёмкостная сложность (space complexity) — это максимальный возможный размер занятой алгоритмом дополнительной памяти, как функция от размера входных данных.
1. Тут три ключевых части: Это функция. Зависит от размера входных данных. Возвращает максимум операций/памяти на всех входах такого размера. То есть **для худшего, самого затратного случая**.
   
   Пример
   ```
    for (let i=0; i < n; i++)
    count++;
    ```
    Посчитаем количество элементарных операций:
    ```
    1 для int i = 0
    n+1 для i < n
    2n для i++ (что эквивалентно i = i + 1, а это две операции: присваивание и сложение)
    2n для сount++
   ```
    Получаем, что временную сложность алгоритма C(n) = 2 + 5nC(n)=2+5n.

## Асимптотическая оценка
1. Если кратко и грубо, то получить асимптотическую оценку можно так: отбросьте в функции сложности все слагаемые, кроме одного с самой быстрой скоростью роста. А потом отбросьте все константы. То что получится и будет асимптотической оценкой сложности.
1. Обычно время работы алгоритма нас интересует на больших данных, когда алгоритм может существенно замедлиться. Асимптотическая оценка как раз отвечает на вопрос, как сильно деградирует производительность с ростом размера входа.

## O-нотация
1. O(n²) (произносится: о от эн квадрат), Θ(n log(n)) (произносится: тэта от эн лог эн).
1. Если очень кратко — O(n²) означает, что **самое быстро растущее слагаемое** в функции сложности — это n в степени не более 2, 
1. Θ(n²) — что степень в точности 2.

### Неформальные трактовки
1. «f = O(g)» можно трактовать так: «функция f(n) растет не быстрее, чем функция g(n) с ростом n» (Знак равенства в записи «f = O(g)» не настоящее равенство.)
1. «f = Θ(g)» — это соответственно «f растет так же быстро, как и g (если игнорировать различия в константном множителе)».
1. При беглом анализе алгоритма, нам не нужна функция сложности, а достаточно лишь её оценки.

    Пример
    ```
    let i = 1;
    while (i < n) {
      for(let j = 0; j < n-2; j++)
        count++;
      i++;
    }
    ```
1. Необходимо найти самую «горячую» операцию — ту, которая выполняется больше всего раз. Чаще всего такая операция находится внутри самого вложенного цикла. 
    Такая операция count++ или j++ внутри for
1. Заметим, что count++ выполняется чуть меньше n² раз. Не точно n², потому что i начинается с 1, а не с нуля, да и внутренний цикл до n-2.  
    В этом случае, например, точное количество выполнений count++ — это (n-1)*(n-2) = Θ(n²).
    Все остальные операции не изменят асимптотику, поэтому их можно даже не рассматривать.
    Значит оценка сложности этого кода и есть Θ(n²).
1. Благодаря переходу от функции сложности к асимптотической оценке, процесс анализа алгоритма становится действительно быстрым и простым.
    Мы оцениваем сложность алгоритма, чтобы убедиться, что он не будет «тормозить». 
    Асимптотическая оценка даёт нам примерное представление, при каком размере задачи (того самого n, от которого зависит функция сложности), можно ожидать приемлемой скорости выполнения.